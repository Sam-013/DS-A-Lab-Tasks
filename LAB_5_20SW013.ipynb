{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo0WmF38AIw9V7aDjleU5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-013/DS-A-Lab-Tasks/blob/main/LAB_5_20SW013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB: 05 TASKS\n",
        "ROLL NUMBER: 20SW013\n",
        "SECTION-1"
      ],
      "metadata": {
        "id": "2LPkm5Ml64lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1"
      ],
      "metadata": {
        "id": "t3NRVQ557AaD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZLVZVBv64Dq",
        "outputId": "abe44674-eab4-4be2-9a13-6888da41076a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earth    149.6\n",
            "Mars     227.9\n",
            "Venus    108.2\n",
            "dtype: float64\n",
            "Earth       149.6\n",
            "Saturn     1433.5\n",
            "Mars        227.9\n",
            "Venus       108.2\n",
            "Jupiter     778.6\n",
            "dtype: float64\n",
            "Earth       8.311111\n",
            "Saturn     79.638889\n",
            "Mars       12.661111\n",
            "Venus       6.011111\n",
            "Jupiter    43.255556\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "distance_from_sun = [149.6, 1433.5, 227.9, 108.2, 778.6]\n",
        "planets = ['Earth', 'Saturn', 'Mars', 'Venus', 'Jupiter']\n",
        "\n",
        "dist_planets = pd.Series(distance_from_sun, index=planets)\n",
        "\n",
        "speed_of_light = 18\n",
        "time_light = dist_planets / speed_of_light\n",
        "\n",
        "close_planets = dist_planets[time_light < 40]\n",
        "\n",
        "print(close_planets)\n",
        "print(dist_planets)\n",
        "print(time_light)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2"
      ],
      "metadata": {
        "id": "BcH4c_g-7s7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "books = pd.Series(data=['Great Expectations', 'Of Mice and Men', 'Romeo and Juliet', 'The Time Machine', 'Alice in Wonderland'])\n",
        "\n",
        "authors = pd.Series(data=['Charles Dickens', 'John Steinbeck', 'William Shakespeare', ' H. G. Wells', 'Lewis Carroll'])\n",
        "\n",
        "user_1 = pd.Series(data=[3.2, np.nan, 2.5])\n",
        "\n",
        "user_2 = pd.Series(data=[5., 1.3, 4.0, 3.8])\n",
        "\n",
        "user_3 = pd.Series(data=[2.0, 2.3, np.nan, 4])\n",
        "\n",
        "user_4 = pd.Series(data=[4, 3.5, 4, 5, 4.2])\n",
        "\n",
        "dat = {\n",
        "    'Author': authors,\n",
        "    'Book Title': books,\n",
        "    'User 1': user_1,\n",
        "    'User 2': user_2,\n",
        "    'User 3': user_3,\n",
        "    'User 4': user_4\n",
        "}\n",
        "\n",
        "book_ratings = pd.DataFrame(dat)\n",
        "\n",
        "book_ratings.fillna(book_ratings.mean(), inplace=True)\n",
        "\n",
        "print(book_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlEUIFnb7udz",
        "outputId": "36e513c4-de48-483b-f077-024b4f0615a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Author           Book Title  User 1  User 2  User 3  User 4\n",
            "0      Charles Dickens   Great Expectations     3.2     5.0     2.0     4.0\n",
            "1       John Steinbeck      Of Mice and Men     2.9     1.3     2.3     3.5\n",
            "2  William Shakespeare     Romeo and Juliet     2.5     4.0     2.8     4.0\n",
            "3          H. G. Wells     The Time Machine     2.9     3.8     4.0     5.0\n",
            "4        Lewis Carroll  Alice in Wonderland     2.9     3.5     2.8     4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4981ddc1aa4b>:29: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  book_ratings.fillna(book_ratings.mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3 Mini project: Jupyter notebook, and data files are attached to the teamâ€™s assignment.\n"
      ],
      "metadata": {
        "id": "T9MZTmwP8lLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistics from Stock Data\n",
        "In this lab we will load stock data into a Pandas Dataframe and calculate some statistics on it. We will be working with stock data from Google, Apple, and Amazon. All the stock data was downloaded from yahoo finance in CSV format. In your workspace you should have a file named GOOG.csv containing the Google stock data, a file named AAPL.csv containing the Apple stock data, and a file named AMZN.csv containing the Amazon stock data. (You can see the workspace folder by clicking on the Jupyter logo in the upper left corner of the workspace.) All the files contain 7 columns of data:\n",
        "\n",
        "Date Open High Low Close Adj_Close Volume\n",
        "\n",
        "We will start by reading in any of the above CSV files into a DataFrame and see what the data looks like."
      ],
      "metadata": {
        "id": "1Md6AFvP-kXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./GOOG.csv')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NUsnUBvk-lcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Do\n",
        "You will now load the stock data from Google, Apple, and Amazon into separte DataFrames. However, for each stock data you will only be interested in loading the Date and Adj Close columns into the Dataframe. In addtion, you want to use the Date column as your row index. Finally, you want the DataFrame to recognize the dates as actual dates (year/month/day) and not as strings. For each stock, you can accomplish all theses things in just one line of code by using the appropiate keywords in the pd.read_csv() function. Here are a few hints:\n",
        "\n",
        "Use the index_col keyword to indicate which column you want to use as an index. For example index_col = ['Open']\n",
        "\n",
        "Set the parse_dates keyword equal to True to convert the Dates into real dates of the form year/month/day\n",
        "\n",
        "Use the usecols keyword to select which columns you want to load into the DataFrame. For example usecols = ['Open', 'High']\n",
        "\n",
        "Fill in the code below:"
      ],
      "metadata": {
        "id": "a8HFCXZK-oyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_stock = pd.read_csv('./GOOG.csv', usecols=['Date', 'Adj Close'], parse_dates=['Date'], index_col=['Date'])\n",
        "\n",
        "apple_stock = pd.read_csv('AAPL.csv', usecols=['Date', 'Adj Close'], parse_dates=['Date'], index_col=['Date'])\n",
        "\n",
        "amazon_stock = pd.read_csv('AMZN.csv', usecols=['Date', 'Adj Close'], parse_dates=['Date'], index_col=['Date'])"
      ],
      "metadata": {
        "id": "4M88UW-_-2KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that you have loaded the data correctly by displaying the head of the DataFrames."
      ],
      "metadata": {
        "id": "ZYjY5MEm-5bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_stock.head()"
      ],
      "metadata": {
        "id": "Hmw25NkL-9fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will now join the three DataFrames above to create a single new DataFrame that contains all the Adj Close for all the stocks. Let's start by creating an empty DataFrame that has as row indices calendar days between 2000-01-01 and 2016-12-31. We will use the pd.date_range() function to create the calendar dates first and then we will create a DataFrame that uses those dates as row indices:"
      ],
      "metadata": {
        "id": "nErlZpa6-_5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates = pd.date_range('2000-01-01', '2016-12-31')\n",
        "\n",
        "all_stocks = pd.DataFrame(index = dates)"
      ],
      "metadata": {
        "id": "_sX6bQE0_DWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Do\n",
        "You will now join the the individual DataFrames, google_stock, apple_stock, and amazon_stock, to the all_stocks DataFrame. However, before you do this, it is necessary that you change the name of the columns in each of the three dataframes. This is because the column labels in the all_stocks dataframe must be unique. Since all the columns in the individual dataframes have the same name, Adj Close, we must change them to the stock name before joining them. In the space below change the column label Adj Close of each individual dataframe to the name of the corresponding stock. You can do this by using the pd.DataFrame.rename() function."
      ],
      "metadata": {
        "id": "17gHS9Oa_FLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_stock = google_stock.rename(columns={'Adj Close': 'Google'})\n",
        "\n",
        "apple_stock = apple_stock.rename(columns={'Adj Close': 'Apple'})\n",
        "\n",
        "amazon_stock = amazon_stock.rename(columns={'Adj Close': 'Amazon'})"
      ],
      "metadata": {
        "id": "pIsPl468_IBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that the column labels have been changed correctly by displaying the datadrames"
      ],
      "metadata": {
        "id": "zE5E7RfD_Kpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_stock.head()"
      ],
      "metadata": {
        "id": "ZXKrTmPF_Mk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we have unique column labels, we can join the individual DataFrames to the all_stocks DataFrame. For this we will use the dataframe.join() function. The function dataframe1.join(dataframe2) joins dataframe1 with dataframe2. We will join each dataframe one by one to the all_stocks dataframe. Fill in the code below to join the dataframes, the first join has been made for you:"
      ],
      "metadata": {
        "id": "Ws2qIBi0_O9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_stocks = all_stocks.join(google_stock)\n",
        "\n",
        "all_stocks = all_stocks.join(apple_stock)\n",
        "\n",
        "all_stocks = all_stocks.join(amazon_stock)"
      ],
      "metadata": {
        "id": "4o9iMol5_RFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that the dataframes have been joined correctly by displaying the all_stocks dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "7N-w6Pdf_SvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_stocks.head()"
      ],
      "metadata": {
        "id": "0NoFlKNU_XUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Do\n",
        "Before we proceed to get some statistics on the stock data, let's first check that we don't have any NaN values. In the space below check if there are any NaN values in the all_stocks dataframe. If there are any, remove any rows that have NaN values:"
      ],
      "metadata": {
        "id": "_TMk5fQr_awa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nan_check = all_stocks.isna().any()\n",
        "\n",
        "\n",
        "print(nan_check)\n",
        "\n",
        "\n",
        "all_stocks = all_stocks.dropna()"
      ],
      "metadata": {
        "id": "kEXLms-e_doQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have eliminated any NaN values we can now calculate some basic statistics on the stock prices. Fill in the code below"
      ],
      "metadata": {
        "id": "R9b3zoN1_fui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Average Stock Price:\")\n",
        "print(all_stocks.mean())\n",
        "\n",
        "print(\"\\nMedian Stock Price:\")\n",
        "print(all_stocks.median())\n",
        "\n",
        "print(\"\\nStandard Deviation of Stock Price:\")\n",
        "print(all_stocks.std())\n",
        "\n",
        "print(\"\\nCorrelation between Stocks:\")\n",
        "print(all_stocks.corr())"
      ],
      "metadata": {
        "id": "_2HSPeXg_iJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will now look at how we can compute some rolling statistics, also known as moving statistics. We can calculate for example the rolling mean (moving average) of the Google stock price by using the Pandas dataframe.rolling().mean() method. The dataframe.rolling(N).mean() calculates the rolling mean over an N-day window. In other words, we can take a look at the average stock price every N days using the above method. Fill in the code below to calculate the average stock price every 150 days for Google stock"
      ],
      "metadata": {
        "id": "u8UvkbC__ktr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rollingMean = google_stock['Google'].rolling(window=150).mean()\n",
        "\n",
        "print(rollingMean)"
      ],
      "metadata": {
        "id": "FCXE5m___m6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the rolling mean by plotting the data in our dataframe. In the following lessons you will learn how to use Matplotlib to visualize data. For now I will just import matplotlib and plot the Google stock data on top of the rolling mean. You can play around by changing the rolling mean window and see how the plot changes."
      ],
      "metadata": {
        "id": "iQcSyAdx_o26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_stocks['Google'])\n",
        "\n",
        "plt.plot(rollingMean)\n",
        "plt.legend(['Google Stock Price', 'Rolling Mean'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iItkt8m7_rN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}